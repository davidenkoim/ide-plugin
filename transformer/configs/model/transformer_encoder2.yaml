# @package _group_

name_of_run: transformer_encoder2

use_camel_case_tokenizer: False
max_epochs: 300
max_sequence_length: 11
max_num_usages: 10
max_target_length: 6
embedding_dim: 256
usage_embedding_dim: 256
target_embedding_dim: 256
num_heads: 8
num_encoder_layers: 2
num_usage_layers: 2
num_decoder_layers: 4
dropout: 0.3
lr: 1e-4
batch_size: 256
sequence_encoder_type: transformer
gpus: 1
