{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adverse-tattoo",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ruled-fashion",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.idDataModule import IdDataModule\n",
    "from model.idTransformerModel import IdTransformerModel\n",
    "import hydra\n",
    "from omegaconf import OmegaConf\n",
    "from tqdm.auto import trange, tqdm\n",
    "import warnings\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dependent-chapter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building train dataset...\n",
      "Building val dataset...\n",
      "Building test dataset...\n",
      "Loading usage counter from C:\\Users\\Igor\\IdeaProjects\\ide-plugin\\dataset\\java-small\\usage_vocab.json\n",
      "Loading target counter from C:\\Users\\Igor\\IdeaProjects\\ide-plugin\\dataset\\java-small\\target_vocab.json\n",
      "\n",
      "Usage vocabulary size is 23418\n",
      "Target vocabulary size is 14377\n"
     ]
    }
   ],
   "source": [
    "conf = OmegaConf.load('configs/config.yaml')\n",
    "conf['model'] = OmegaConf.load('configs/model/transformer_encoder.yaml')\n",
    "conf['dataset'] = OmegaConf.load('configs/dataset/java-small.yaml')\n",
    "conf.dataset.usage_vocab_min_freq = 3\n",
    "conf.dataset.target_vocab_min_freq = 2\n",
    "def dm(cfg):\n",
    "    datamodule = IdDataModule(cfg)\n",
    "    datamodule.setup('test')\n",
    "    return datamodule\n",
    "\n",
    "dm = dm(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "meaning-ending",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IdTransformerModel.load_from_checkpoint(r\"checkpoints/11.03-transformer_encoder-java-small-epoch=02-val_accuracy=0.19.ckpt\",\n",
    "                                               map_location=\"cpu\",\n",
    "                                               dm=dm,\n",
    "                                               cfg=conf.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "nearby-funeral",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = dm.dataset.target_vocabulary\n",
    "def itos(ids):\n",
    "    ids.reshape(-1)\n",
    "    return list(map(lambda x: vocab.itos[x], ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "employed-optimum",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model.train(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adjacent-special",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.manual_seed(42)\n",
    "iterator = iter(DataLoader(dm.dataset.test,\n",
    "                                       batch_size=1,\n",
    "                                       shuffle=True,\n",
    "                                       collate_fn=dm.dataset.collate_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "proprietary-calculator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[torchtext.legacy.data.batch.Batch of size 1]\n",
       "\t[.target]:('[torch.LongTensor of size 6x1]', '[torch.LongTensor of size 1]')\n",
       "\t[.usages]:[torch.LongTensor of size 1x11x41]"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex = next(iterator)\n",
    "ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "bigger-humanitarian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>', 'rpc', 'server', '</s>', '<pad>', '<pad>']"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itos(ex.target[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "separate-wallpaper",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>', 'server', '</s>']: 0.043029683704450546\n",
      "['<s>', 'port', '</s>']: 0.030609993522448243\n",
      "['<s>', 'coordinator', '</s>']: 0.020024495759689228\n",
      "['<s>', 'connector', '</s>']: 0.017832930840474857\n",
      "['<s>', 'discovery', 'node', '</s>']: 0.017712834854850104\n",
      "['<s>', 'host', '</s>']: 0.0168719493946595\n",
      "['<s>', 'node', '</s>']: 0.014936942953890624\n",
      "['<s>', 'server', 'node', '</s>']: 0.014028782476434826\n",
      "['<s>', 'hostname', '</s>']: 0.01330560722522888\n",
      "['<s>', 'server', 'port', '</s>']: 0.009655817536823354\n",
      "0.19800903826895017\n"
     ]
    }
   ],
   "source": [
    "sum_p = 0\n",
    "for pred in model(ex.usages[0], batch_size=10, beam_width=40, topk=10):\n",
    "    sum_p += pred[1].p\n",
    "    print(f\"{itos(pred[1].token_ids)}: {pred[1].p}\")\n",
    "print(sum_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "transsexual-reduction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255 ms ± 25.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit model(ex.usages[0], batch_size=None, beam_width=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "identical-destruction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98 ms ± 2.24 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit model(ex.usages[0], batch_size=10, beam_width=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "breathing-passage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151 ms ± 1.21 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit model(ex.usages[0], batch_size=20, beam_width=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "linear-reunion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119 ms ± 1.56 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit model(ex.usages[0], batch_size=30, beam_width=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "developmental-formation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144 ms ± 4.89 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit model(ex.usages[0], batch_size=40, beam_width=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecological-clearance",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
