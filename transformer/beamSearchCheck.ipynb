{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "reasonable-duplicate",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "short-disabled",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.idDataModule import IdDataModule\n",
    "from model.idTransformerModel import IdTransformerModel\n",
    "import hydra\n",
    "from omegaconf import OmegaConf\n",
    "from tqdm.auto import trange, tqdm\n",
    "import warnings\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "announced-introduction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building train dataset...\n",
      "Building val dataset...\n",
      "Building test dataset...\n",
      "Loading usage counter from C:\\Users\\Igor\\IdeaProjects\\ide-plugin\\build\\idea-sandbox\\system\\dataset\\java-small\\usage_vocab.json\n",
      "Loading target counter from C:\\Users\\Igor\\IdeaProjects\\ide-plugin\\build\\idea-sandbox\\system\\dataset\\java-small\\target_vocab.json\n",
      "\n",
      "Usage vocabulary size is 23418\n",
      "Target vocabulary size is 14377\n"
     ]
    }
   ],
   "source": [
    "conf = OmegaConf.load('configs/config.yaml')\n",
    "conf['model'] = OmegaConf.load('configs/model/transformer_encoder.yaml')\n",
    "conf.model.batch_size = 1\n",
    "conf.model.max_num_usages = None\n",
    "conf['dataset'] = OmegaConf.load('configs/dataset/java-small.yaml')\n",
    "conf.dataset.usage_vocab_min_freq = 3\n",
    "conf.dataset.target_vocab_min_freq = 2\n",
    "def dm(cfg):\n",
    "    datamodule = IdDataModule(cfg)\n",
    "    datamodule.setup('fit')\n",
    "    return datamodule\n",
    "\n",
    "dm = dm(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ignored-ultimate",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IdTransformerModel.load_from_checkpoint(r\"checkpoints/11.03-transformer_encoder-java-small-epoch=02-val_accuracy=0.19.ckpt\",\n",
    "                                               map_location=\"cpu\",\n",
    "                                               dm=dm,\n",
    "                                               cfg=conf.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "square-chess",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = dm.dataset.target_vocabulary\n",
    "def itos(ids):\n",
    "    ids.reshape(-1)\n",
    "    return list(map(lambda x: vocab.itos[x], ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "prospective-tobacco",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model.train(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "developed-promise",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.manual_seed(42)\n",
    "iterator = iter(DataLoader(dm.dataset.test,\n",
    "                                       batch_size=1,\n",
    "                                       shuffle=True,\n",
    "                                       collate_fn=dm.dataset.collate_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "secret-airplane",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[torchtext.data.batch.Batch of size 1]\n",
       "\t[.target]:('[torch.LongTensor of size 6x1]', '[torch.LongTensor of size 1]')\n",
       "\t[.usages]:('[torch.LongTensor of size 1x5x41]', '[torch.LongTensor of size 1]', '[torch.LongTensor of size 1x5]')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex = next(iterator)\n",
    "ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "compliant-external",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>', 'pending', 'event', 'queue', '</s>', '<pad>']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itos(ex.target[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "chief-yorkshire",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>', 'queue', '</s>']: 0.3604006853478108\n",
      "['<s>', '<unk>', '</s>']: 0.020605530450632493\n",
      "['<s>', 'event', 'queue', '</s>']: 0.017151209875754917\n",
      "['<s>', 'pending', 'queue', '</s>']: 0.014578924691573953\n",
      "['<s>', 'queue', 'queue', '</s>']: 0.011628744575718138\n",
      "['<s>', 'schedule', 'queue', '</s>']: 0.01110532901054162\n",
      "['<s>', 'waiting', 'queue', '</s>']: 0.009525916241712649\n",
      "['<s>', 'work', 'queue', '</s>']: 0.008030421008509207\n",
      "['<s>', 'locks', '</s>']: 0.005735279604092989\n",
      "['<s>', 'clients', '</s>']: 0.004684474300920446\n",
      "0.46344651510726725\n"
     ]
    }
   ],
   "source": [
    "sum_p = 0\n",
    "for pred in model(ex.usages[0]):\n",
    "    sum_p += pred[1].p\n",
    "    print(f\"{itos(pred[1].token_ids)}: {pred[1].p}\")\n",
    "print(sum_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "thousand-great",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156 ms ± 10 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit model(ex.usages[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
